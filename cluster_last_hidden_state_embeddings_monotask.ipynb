{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4aee6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AffinityPropagation, AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2a06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_tSNE(emb_matrix, word_types):\n",
    "    print(\"Running tSNE on\", emb_matrix.shape, \"-dim data\")\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=30, n_iter=250)\n",
    "    tsne_results = tsne.fit_transform(emb_matrix)\n",
    "    print('t-SNE done!')\n",
    "    df_tsne = {'word_type': word_types}\n",
    "    df_tsne['ax1'] = tsne_results[:, 0]\n",
    "    df_tsne['ax2'] = tsne_results[:, 1]\n",
    "    ### Plot data with Plotly\n",
    "    fig = px.scatter(df_tsne,\n",
    "                     x='ax1',\n",
    "                     y='ax2',\n",
    "                     color='word_type',\n",
    "                     opacity=0.3\n",
    "                     )\n",
    "    fig.update_traces(mode='markers', marker_size=8)\n",
    "    fig.update_layout(coloraxis={\"colorbar\":{\"dtick\":1}})\n",
    "    fig.update_xaxes(visible=False, showticklabels=False)\n",
    "    fig.update_yaxes(visible=False, showticklabels=False)\n",
    "    fig.update_layout(legend=dict(font=dict(size=10)))\n",
    "    fig.show()\n",
    "    #save_filename = \"figures/ctm_topic_space-tsne-train3000-no_bg.html\"\n",
    "    #fig.write_html(save_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4ac3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_PCA(emb_matrix, word_types):\n",
    "    print(\"Running PCA on\", emb_matrix.shape, \"-dim matrix\")\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(emb_matrix)\n",
    "    df_pca = {'word_type': word_types}\n",
    "    df_pca['PC1'] = pca_result[:, 0]\n",
    "    df_pca['PC2'] = pca_result[:, 1]\n",
    "    ### Plot data with Plotly\n",
    "    fig = px.scatter(df_pca,\n",
    "                     x='PC1',\n",
    "                     y='PC2',\n",
    "                     color='word_type',\n",
    "                     opacity=0.3\n",
    "                     )\n",
    "    fig.update_traces(mode='markers', marker_size=8)\n",
    "    fig.update_layout(coloraxis={\"colorbar\":{\"dtick\":1}})\n",
    "    fig.update_xaxes(visible=False, showticklabels=False)\n",
    "    fig.update_yaxes(visible=False, showticklabels=False)\n",
    "    # fig.update_layout(paper_bgcolor=\"rgba(0,0,0,0)\", plot_bgcolor=\"rgba(0,0,0,0)\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d02caf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd396c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task\n",
       "C    96720\n",
       "P    96720\n",
       "T    96720\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = ['P', 'C', 'T']\n",
    "\n",
    "df = pd.read_csv(\"concreteness_norms_last_hidden_state_embs.csv\")\n",
    "\n",
    "df[\"task\"] = [m.split(\"/\")[0] for m in df.model.tolist()]\n",
    "df[\"task\"].replace(to_replace=\"paraphrase\", value=\"P\", inplace=True)\n",
    "df[\"task\"].replace(to_replace=\"captioning\", value=\"C\", inplace=True)\n",
    "df[\"task\"].replace(to_replace=\"translation\", value=\"T\", inplace=True)\n",
    "df.task.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc175d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n",
      "mean: 0.8300925925925926\n",
      "std: 0.025977241198298077\n",
      "Task: C\n",
      "mean: 0.8281449553001277\n",
      "std: 0.02948014977946599\n",
      "Task: T\n",
      "mean: 0.8480683269476372\n",
      "std: 0.018720610517980726\n"
     ]
    }
   ],
   "source": [
    "# KMeans\n",
    "\n",
    "def compute_purity(data):\n",
    "    emb_matrix = np.array(data.iloc[:,:512])\n",
    "    true_labels = data.word_type.tolist()\n",
    "    kmeans = KMeans(n_clusters=2).fit(emb_matrix)\n",
    "    y_pred = kmeans.labels_\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    # print('purity:', purity)\n",
    "    return purity\n",
    "\n",
    "def compute_purity_balance_data(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(frac=1)\n",
    "        concrete = concrete[:word_type_counts['abstract']]\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    kmeans = KMeans(n_clusters=2).fit(emb_matrix)\n",
    "    y_pred = kmeans.labels_\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    # print('purity:', purity)\n",
    "    return purity\n",
    "\n",
    "task_purity = {'task':[], \n",
    "               'purity':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_purity = task_models.groupby(\"model\").apply(lambda x: compute_purity_balance_data(x))\n",
    "    print('mean:', model_purity.mean())\n",
    "    print('std:', model_purity.std())\n",
    "    task_purity['purity'].extend(model_purity.tolist())\n",
    "    task_purity['task'].extend([task]*len(model_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f851143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='task', ylabel='purity'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUGUlEQVR4nO3df6zd9X3f8efL9qgB86MZFghfCDQmgJUV2t7SlGwNDS0/2jSoWqeCmm2y1iJUmEn3C6pVpRNoyxZokzuzWSyhpEtUNFGmArNKujRElCwZNjZ1bEp8a4i5MU0vQRAIUGL83h/noB2OP4aDuV+fe32fD8ny+f68L/vKft3vr883VYUkScOWjDuAJGl+siAkSU0WhCSpyYKQJDVZEJKkpmXjDjCXTjjhhDrttNPGHUOSFozNmzc/U1UrW8sOq4I47bTT2LRp07hjSNKCkeSbB1rmKSZJUpMFIUlq6rQgklyS5PEk00mubyw/Lsm9SR5Nsj3J2oFlv9Gf9/Ukf5hkeZdZJUlv1FlBJFkK3ApcCqwBrkiyZmi1q4EdVXUOcAFwS5IjkqwC1gGTVfU+YClweVdZJUn76/II4jxguqp2VdWrwJ3AZUPrFHBMkgArgGeBvf1ly4AjkywDjgL2dJhVkjSky4JYBTw1MD3TnzdoPXA2vf/8twHXVtW+qvoWcDOwG3gaeL6qvtBhVknSkC4LIo15w0PHXgxsBU4GzgXWJzk2yQ/SO9o4vb/s6CQfbX6R5Mokm5Jsmp2dnavskrTodfkcxAxwysD0BPufJloLfLx6Y45PJ3kCOAt4N/BEVc0CJLkbOB/43PAXqarbgNsAJicnHbtcB21qaorp6ek53+/MzAwAExMTc77v1atXs27dujnfrwTdHkE8DJyR5PQkR9C7yHzP0Dq7gQsBkpwInAns6s9/f5Kj+tcnLgQe6zCr1JmXX36Zl19+edwxpLetsyOIqtqb5Brgfnp3Id1eVduTXNVfvgG4EbgjyTZ6p6Suq6pngGeS3AU8Qu+i9Rb6RwlSV7r6Sfz1/U5NTXWyf6krnQ61UVUbgY1D8zYMfN4DXHSAbW8AbugynyTpwHySWpLUZEFIkposCElSkwUhSWo6rN4HMW4L8T568F56LXxd/duDxf0ciwWxAHgPvTQ+i/nfnwUxh7yPXhqPLn8KX8z//rwGIUlqsiAkSU0WhCSpyYKQJDVZEJKkJgtCktRkQUiSmiwISVKTBSFJarIgJElNFoQkqcmCkCQ1WRCSpCYLQpLUZEFIkposCElSkwUhSWqyICRJTRaEJKnJgpAkNVkQkqSmZeMOIGnxmJqaYnp6etwx3padO3cCsG7dujEnGd3q1avnJK8FIemQmZ6eZsv2LXD8uJO8Dft6v2351pbx5hjVc3O3KwtC0qF1POy7YN+4Uxy2ljwwd1cOOr0GkeSSJI8nmU5yfWP5cUnuTfJoku1J1g4sOz7JXUn+MsljSX6yy6ySpDfqrCCSLAVuBS4F1gBXJFkztNrVwI6qOge4ALglyRH9ZZ8C/qSqzgLOAR7rKqskaX9dHkGcB0xX1a6qehW4E7hsaJ0CjkkSYAXwLLA3ybHATwGfAaiqV6vquQ6zSpKGdFkQq4CnBqZn+vMGrQfOBvYA24Brq2of8EPALPD7SbYk+XSSo1tfJMmVSTYl2TQ7OzvnfwhJWqy6LIg05tXQ9MXAVuBk4Fxgff/oYRnwo8B/raofAb4H7HcNA6CqbquqyaqaXLly5RxFlyR1WRAzwCkD0xP0jhQGrQXurp5p4AngrP62M1X1tf56d9ErDEnSIdJlQTwMnJHk9P6F58uBe4bW2Q1cCJDkROBMYFdV/TXwVJIz++tdCOzoMKskaUhnz0FU1d4k1wD3A0uB26tqe5Kr+ss3ADcCdyTZRu+U1HVV9Ux/F/8c+Hy/XHbRO9rQIueTuIfOXD2Nq4Wr0wflqmojsHFo3oaBz3uAiw6w7VZgsst8Wnimp6f5xtcf4dQVr407ysiO+H7vQP2VJx8ec5LR7X5x6bgjaB7wSWotOKeueI3fmnxx3DEOazdtWjHuCJoHFmVBLLTTFJ6i0OFiZmYGnp/b4SA05DmYqZk52dWiLIjp6Wm2bNvBvqPeNe4oI8mrvbuDN//VX485yeiWvPTsuCNIeocWZUEA7DvqXbyy5sPjjnHYWr7jvnFH0Dw0MTHBbGYdrK9DSx5YwsSqibnZ15zsRZJ02LEgJElNFoQkqcmCkCQ1WRCSpCYLQpLUZEFIkposCElSkwUhSWqyICRJTRaEJKnJgpAkNVkQkqQmC0KS1GRBSJKaLAhJUpMFIUlqsiAkSU0WhCSpyYKQJDVZEJKkJgtCktRkQUiSmiwISVKTBSFJarIgJElNnRZEkkuSPJ5kOsn1jeXHJbk3yaNJtidZO7R8aZItSe7rMqckaX+dFUSSpcCtwKXAGuCKJGuGVrsa2FFV5wAXALckOWJg+bXAY11llCQdWJdHEOcB01W1q6peBe4ELhtap4BjkgRYATwL7AVIMgH8PPDpDjNKkg6gy4JYBTw1MD3TnzdoPXA2sAfYBlxbVfv6yz4J/BtgH28iyZVJNiXZNDs7Oxe5JUl0WxBpzKuh6YuBrcDJwLnA+iTHJvkw8DdVtfmtvkhV3VZVk1U1uXLlyncYWZL0ui4LYgY4ZWB6gt6RwqC1wN3VMw08AZwFfAD4SJIn6Z2a+lCSz3WYVZI0pMuCeBg4I8np/QvPlwP3DK2zG7gQIMmJwJnArqr6zaqaqKrT+tv9WVV9tMOskqQhy7racVXtTXINcD+wFLi9qrYnuaq/fANwI3BHkm30TkldV1XPdJVJkjS6zgoCoKo2AhuH5m0Y+LwHuOgt9vEA8EAH8SRJb8InqSVJTRaEJKnJgpAkNVkQkqQmC0KS1DRSQfQH3pMkLSKjHkFMJ/lEYzRWSdJhatSC+GHgG8Cnk3y1P0DesR3mkiSN2UgFUVUvVNV/q6rz6Y2wegPwdJLPJlndaUJJ0liMfA0iyUeS/E/gU8AtwA8B9zL0pLQk6fAw6lAbO4EvAZ+oqq8MzL8ryU/NfSxJ0riNWhD/pKr+fHBGkg9U1UNVta6DXJKkMRv1IvVUY95/nssgkqT55U2PIJL8JHA+sDLJvxhYdCy9IbwlSYeptzrFdASwor/eMQPzvwv8UlehujYzM8OSl55n+Y77xh3lsLXkpe8wM7N33DE0Hz0HSx5YQIM4vNj/fcVYU4zuOWDV3OzqTQuiqr4MfDnJHVX1zbn5kpIWq9WrF95d8Tt37gTgjFVnjDnJiFbN3d/zW51i+mRVfQxYn6SGl1fVR+YkxSE2MTHBt/92Ga+s+fC4oxy2lu+4j4mJk8YdQ/PMunUL756W1zNPTbUuxR7e3uoU03/v/35z10EkSfPLW51i2twfqO/XquqjhyiTJGkeeMsrRVX1Gr27mI44BHkkSfPEqA/KPQk8lOQe4Huvz6yq3+0ilCRp/EYtiD39X0t44+2ukqTD1EgFUVX/rusgkqT5ZaSCSPIloHWb64fmPJEkaV4Y9RTTvxr4vBz4h4CPyUrSYWzUU0ybh2Y9lOTLHeSRJM0To55ietfA5BJgEvAxWUk6jI16imkz//8axF56t73+sy4CSZLmh1ELYg3w68Dfp1cUDwKbugolSRq/UQvis/SG+H59tKor6I3T9I+6CCVJGr9RB2U/s6p+taq+1P91JfDet9ooySVJHk8yneT6xvLjktyb5NEk25Os7c8/JcmXkjzWn3/t2/tjSZLeqVGPILYkeX9VfRUgyU8AD73ZBv1B/m4FfhaYAR5Ock9V7RhY7WpgR1X9QpKVwONJPk/vOse/rKpHkhwDbE7yp0PbahGamZnhey8s5aZNC+XtLQvTN19YytEzM+OOoTEb9QjiJ4CvJHkyyZPA/wE+mGRbkr84wDbnAdNVtauqXgXuBC4bWqeAY5KE3vuangX2VtXTVfUIQFW9ADzGnL0jSZI0ilGPIC45iH2vAp4amJ6hVzSD1gP30Bvn6Rjgl6tq3+AKSU4DfgT4WuuLJLkSuBLg1FNPPYiYWkgmJiZ4Ze/T/Nbki2+9sg7aTZtWsHxiYtwxNGajPih3MK8bTWtXQ9MXA1uBDwHvAf40yYNV9V2AJCuAPwI+9vq8RrbbgNsAJicn9xsORJJ0cLp8c/gMcMrA9AS9I4VBa4G7q2caeAI4CyDJ36FXDp+vqrs7zClJauiyIB4Gzkhyev9lQ5fTO500aDdwIUCSE4EzgV39axKfAR7znROSNB6dFURV7QWuAe6nd5H5f1TV9iRXJbmqv9qNwPlJtgFfBK6rqmeADwD/GPhQkq39Xz/XVVZJ0v5GvUh9UKpqI7BxaN6Ggc97gIsa2/057WsYkqRDpMtTTJKkBcyCkCQ1WRCSpCYLQpLUZEFIkposCElSU6e3uUrSoTA1NcX09HQn+965cycA69atm/N9r169upP9zhULQpLexJFHHjnuCGNjQUha8ObzT+ELmdcgJElNFoQkqcmCkCQ1WRCSpCYLQpLUtGjvYlry0rMs33HfuGOMJK/03rZay48dc5LRLXnpWeCkcceQ9A4syoJYvXr1uCO8LTt3vgDAGe9ZSP/hnrTg/p4lvdGiLIiFds/063mnpqbGnETSYuI1CElSkwUhSWqyICRJTRaEJKnJgpAkNVkQkqQmC0KS1LQon4PQwrb7xaXctGnFuGOM7Nsv9X4OO/GofWNOMrrdLy7lveMOobGzILSgLMSns1/tv7Jy+WlnjDnJ6N7Lwvy71tyyILSgLLSn4MEn4bVweQ1CktRkQUiSmiwISVJTpwWR5JIkjyeZTnJ9Y/lxSe5N8miS7UnWjrqtJKlbnRVEkqXArcClwBrgiiRrhla7GthRVecAFwC3JDlixG0lSR3q8gjiPGC6qnZV1avAncBlQ+sUcEySACuAZ4G9I24rSepQlwWxCnhqYHqmP2/QeuBsYA+wDbi2qvaNuC0ASa5MsinJptnZ2bnKLkmLXpcFkca8Gpq+GNgKnAycC6xPcuyI2/ZmVt1WVZNVNbly5cqDTytJeoMuC2IGOGVgeoLekcKgtcDd1TMNPAGcNeK2kqQOdVkQDwNnJDk9yRHA5cA9Q+vsBi4ESHIicCawa8RtJUkd6myojaram+Qa4H5gKXB7VW1PclV/+QbgRuCOJNvonVa6rqqeAWht21VWSdL+Oh2Lqao2AhuH5m0Y+LwHuGjUbSVJh45PUkuSmiwISVKTBSFJarIgJElNFoQkqcmCkCQ1WRCSpCYLQpLUZEFIkposCElSkwUhSWqyICRJTRaEJKnJgpAkNVkQkqQmC0KS1GRBSJKaLAhJUpMFIUlqsiAkSU0WhCSpyYKQJDVZEJKkJgtCktRkQUiSmiwISVKTBSFJarIgJElNy8YdQJovpqammJ6envP97ty5E4B169bN+b5Xr17dyX4lsCCkzh155JHjjiAdlE4LIsklwKeApcCnq+rjQ8v/NfArA1nOBlZW1bNJfgP4VaCAbcDaqnqly7xa3PxJXHqjzq5BJFkK3ApcCqwBrkiyZnCdqvpEVZ1bVecCvwl8uV8Oq4B1wGRVvY9ewVzeVVZJ0v66vEh9HjBdVbuq6lXgTuCyN1n/CuAPB6aXAUcmWQYcBezpLKkkaT9dFsQq4KmB6Zn+vP0kOQq4BPgjgKr6FnAzsBt4Gni+qr7QYVZJ0pAuCyKNeXWAdX8BeKiqngVI8oP0jjZOB04Gjk7y0eYXSa5MsinJptnZ2TmILUmCbgtiBjhlYHqCA58mupw3nl76GeCJqpqtqu8DdwPntzasqtuqarKqJleuXDkHsSVJ0G1BPAyckeT0JEfQK4F7hldKchzwQeCPB2bvBt6f5KgkAS4EHuswqyRpSGe3uVbV3iTXAPfTuwvp9qranuSq/vIN/VV/EfhCVX1vYNuvJbkLeATYC2wBbusq61xZiA9agQ9bSWrr9DmIqtoIbByat2Fo+g7gjsa2NwA3dBhvwfBBK0nj4JPUc8ifwiUdThysT5LUZEFIkposCElSkwUhSWqyICRJTRaEJKnJgpAkNVkQkqSmVB1ogNWFJ8ks8M1x5+jICcAz4w6hg+b3b2E7nL9/766q5kinh1VBHM6SbKqqyXHn0MHx+7ewLdbvn6eYJElNFoQkqcmCWDjm/XDnelN+/xa2Rfn98xqEJKnJIwhJUpMFIUlq8oVB81yS14Bt9L5XjwH/tKpeGm8qjSrJScAngR8H/hZ4EvhYVX1jjLH0FpL8XeCL/cmTgNeA2f70eVX16liCHWJeg5jnkrxYVSv6nz8PbK6q3x1zLI0gSYCvAJ99/VW7Sc4FjqmqB8eZTaNL8jvAi1V187izHGoeQSwsDwI/PO4QGtlPA98ffA97VW0dXxzp7fEaxAKRZBlwKb3TTVoY3gdsHncI6WB5BDH/HZlka//zg8BnxphF0iJiQcx/L1fVueMOoYOyHfilcYeQDpanmKTu/BnwA0l+7fUZSX48yQfHmEkamQUhdaR6twj+IvCzSf4qyXbgd4A9Yw0mjcjbXCVJTR5BSJKaLAhJUpMFIUlqsiAkSU0WhCSpyYKQ3oEkxyf59YPc9skkJ8x1JmmuWBDSO3M8cFAFIc13FoT0znwceE+SrUl+L8kXkzySZFuSywCSHJ3kfyV5NMnXk/zy4A6SHJnkTwafuJbmA8dikt6Z64H3VdW5/RF3j6qq7/ZPHX01yT3AJcCeqvp5gCTHDWy/ArgT+IOq+oNDHV56Mx5BSHMnwL9P8hfA/wZWASfSG6L9Z5L8xyT/oKqeH9jmj4Hftxw0H1kQ0tz5FWAl8GP9EXi/DSzvv170x+gVxX9I8tsD2zwEXNp/+5w0r1gQ0jvzAnBM//NxwN9U1feT/DTwboAkJwMvVdXngJuBHx3Y/reB7wD/5dBFlkZjQUjvQFV9B3goydeBc4HJJJvoHU38ZX+1vwf83/6Ln/4tcNPQbj4GLE/ynw5FZmlUjuYqSWryCEKS1GRBSJKaLAhJUpMFIUlqsiAkSU0WhCSpyYKQJDX9PxVknNVhuKFtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "task_purity = pd.DataFrame.from_dict(task_purity)\n",
    "sns.boxplot(data=task_purity, x=\"task\", y=\"purity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807c860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs C: KruskalResult(statistic=0.1372807685994792, pvalue=0.7109994019900486)\n",
      "P vs T: KruskalResult(statistic=9.753452632196076, pvalue=0.0017898623520279046)\n",
      "C vs T: KruskalResult(statistic=9.19008511536297, pvalue=0.0024332957481631094)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "P_purity = task_purity[task_purity.task == 'P'].purity.to_list()\n",
    "C_purity = task_purity[task_purity.task == 'C'].purity.to_list()\n",
    "T_purity = task_purity[task_purity.task == 'T'].purity.to_list()\n",
    "print(\"P vs C:\", kruskal(P_purity, C_purity))\n",
    "print(\"P vs T:\", kruskal(P_purity, T_purity))\n",
    "print(\"C vs T:\", kruskal(C_purity, T_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c886e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_type\n",
       "concrete    1635\n",
       "abstract     783\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'translation/downsample-n-none/5/translation_none_e10.pt'\n",
    "concrete = df[(df.model == model_name) & (df.word_type == 'concrete')][:783]\n",
    "abstract = df[(df.model == model_name) & (df.word_type == 'abstract')]\n",
    "balance = pd.concat([concrete, abstract])\n",
    "balance.word_type.value_counts()\n",
    "df[df.model == model_name].word_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e3e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n",
      "mean: 0.05406018950502237\n",
      "std: 0.007379671723261823\n",
      "Task: C\n",
      "mean: 0.04981882097783306\n",
      "std: 0.006457359783491406\n",
      "Task: T\n",
      "mean: 0.05690005209415304\n",
      "std: 0.006605553476357976\n"
     ]
    }
   ],
   "source": [
    "def compute_silhouette_balance_data(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(word_type_counts['abstract'])\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    return metrics.silhouette_score(emb_matrix, true_labels)\n",
    "\n",
    "task_sil = {'task':[], \n",
    "               'sil':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_sil = task_models.groupby(\"model\").apply(lambda x: compute_silhouette_balance_data(x))\n",
    "    print('mean:', model_sil.mean())\n",
    "    print('std:', model_sil.std())\n",
    "    task_sil['sil'].extend(model_sil.tolist())\n",
    "    task_sil['task'].extend([task]*len(model_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890f1600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs C: KruskalResult(statistic=6.259259259259267, pvalue=0.012354585017871901)\n",
      "P vs T: KruskalResult(statistic=1.3556481481481342, pvalue=0.24429312172305379)\n",
      "C vs T: KruskalResult(statistic=11.933425925925917, pvalue=0.0005513569270503431)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "task_sil = pd.DataFrame.from_dict(task_sil)\n",
    "P_sil = task_sil[task_sil.task == 'P'].sil.to_list()\n",
    "C_sil = task_sil[task_sil.task == 'C'].sil.to_list()\n",
    "T_sil = task_sil[task_sil.task == 'T'].sil.to_list()\n",
    "print(\"P vs C:\", kruskal(P_sil, C_sil))\n",
    "print(\"P vs T:\", kruskal(P_sil, T_sil))\n",
    "print(\"C vs T:\", kruskal(C_sil, T_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6760e569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n",
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8876596424010217\n",
      "std: 0.005629279169142971\n",
      "Task: C\n",
      "mean: 0.8901979565772669\n",
      "std: 0.0055272436952821125\n",
      "Task: T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n",
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8857439335887612\n",
      "std: 0.005666304860634319\n"
     ]
    }
   ],
   "source": [
    "# Affinity propagation clustering\n",
    "def purity_score(y_true, y_pred):\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) \n",
    "\n",
    "def compute_purity_balance_data_aff_prop(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(frac=1)\n",
    "        concrete = concrete[:word_type_counts['abstract']]\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    aff_prop = AffinityPropagation().fit(emb_matrix)\n",
    "    y_pred = aff_prop.labels_\n",
    "    #print('emb_matrix:', emb_matrix.shape)\n",
    "    #print('n_clusters:', len(Counter(y_pred)))\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    return purity\n",
    "\n",
    "task_purity_aff_prop = {'task':[], \n",
    "                        'purity':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_purity = task_models.groupby(\"model\").apply(lambda x: compute_purity_balance_data_aff_prop(x))\n",
    "    print('mean:', model_purity.mean())\n",
    "    print('std:', model_purity.std())\n",
    "    task_purity_aff_prop['purity'].extend(model_purity.tolist())\n",
    "    task_purity_aff_prop['task'].extend([task]*len(model_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f4c126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs C: KruskalResult(statistic=5.0370908450290885, pvalue=0.024810121135051055)\n",
      "P vs T: KruskalResult(statistic=1.391604256418099, pvalue=0.23813436589068443)\n",
      "C vs T: KruskalResult(statistic=11.006197908106998, pvalue=0.0009080772546040999)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "task_purity_aff_prop = pd.DataFrame.from_dict(task_purity_aff_prop)\n",
    "P_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'P'].purity.to_list()\n",
    "C_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'C'].purity.to_list()\n",
    "T_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'T'].purity.to_list()\n",
    "print(\"P vs C:\", kruskal(P_purity, C_purity))\n",
    "print(\"P vs T:\", kruskal(P_purity, T_purity))\n",
    "print(\"C vs T:\", kruskal(C_purity, T_purity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea73ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n",
      "mean: 0.9211047254150703\n",
      "std: 0.012498266591078108\n",
      "Task: C\n",
      "mean: 0.9322158365261813\n",
      "std: 0.01107409598039503\n",
      "Task: T\n",
      "mean: 0.9196200510855684\n",
      "std: 0.011397594829936674\n"
     ]
    }
   ],
   "source": [
    "# Agglomerative (hierarchical) clustering\n",
    "def compute_purity_balance_data_agglomerative(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(frac=1)\n",
    "        concrete = concrete[:word_type_counts['abstract']]\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    agg = AgglomerativeClustering(n_clusters=None,\n",
    "                                  metric='cosine',\n",
    "                                  linkage='average',\n",
    "                                 distance_threshold=0.5).fit(emb_matrix)\n",
    "    y_pred = agg.labels_\n",
    "    #print('n_clusters:', len(Counter(y_pred)))\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    return purity\n",
    "\n",
    "task_purity_agg = {'task':[], \n",
    "                   'purity':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_purity = task_models.groupby(\"model\").apply(lambda x: compute_purity_balance_data_agglomerative(x))\n",
    "    print('mean:', model_purity.mean())\n",
    "    print('std:', model_purity.std())\n",
    "    task_purity_agg['purity'].extend(model_purity.tolist())\n",
    "    task_purity_agg['task'].extend([task]*len(model_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb1a058c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs C: KruskalResult(statistic=13.662460856408968, pvalue=0.0002187845853123075)\n",
      "P vs T: KruskalResult(statistic=0.05117084413374062, pvalue=0.8210382995364761)\n",
      "C vs T: KruskalResult(statistic=20.422415825211985, pvalue=6.209815861295692e-06)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "task_purity_agg = pd.DataFrame.from_dict(task_purity_agg)\n",
    "P_purity = task_purity_agg[task_purity_agg.task == 'P'].purity.to_list()\n",
    "C_purity = task_purity_agg[task_purity_agg.task == 'C'].purity.to_list()\n",
    "T_purity = task_purity_agg[task_purity_agg.task == 'T'].purity.to_list()\n",
    "print(\"P vs C:\", kruskal(P_purity, C_purity))\n",
    "print(\"P vs T:\", kruskal(P_purity, T_purity))\n",
    "print(\"C vs T:\", kruskal(C_purity, T_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed68267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
