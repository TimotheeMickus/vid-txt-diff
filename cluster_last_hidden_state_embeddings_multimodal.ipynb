{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4aee6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AffinityPropagation, AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2a06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_tSNE(emb_matrix, word_types):\n",
    "    print(\"Running tSNE on\", emb_matrix.shape, \"-dim data\")\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=30, n_iter=250)\n",
    "    tsne_results = tsne.fit_transform(emb_matrix)\n",
    "    print('t-SNE done!')\n",
    "    df_tsne = {'word_type': word_types}\n",
    "    df_tsne['ax1'] = tsne_results[:, 0]\n",
    "    df_tsne['ax2'] = tsne_results[:, 1]\n",
    "    ### Plot data with Plotly\n",
    "    fig = px.scatter(df_tsne,\n",
    "                     x='ax1',\n",
    "                     y='ax2',\n",
    "                     color='word_type',\n",
    "                     opacity=0.3\n",
    "                     )\n",
    "    fig.update_traces(mode='markers', marker_size=8)\n",
    "    fig.update_layout(coloraxis={\"colorbar\":{\"dtick\":1}})\n",
    "    fig.update_xaxes(visible=False, showticklabels=False)\n",
    "    fig.update_yaxes(visible=False, showticklabels=False)\n",
    "    fig.update_layout(legend=dict(font=dict(size=10)))\n",
    "    fig.show()\n",
    "    #save_filename = \"figures/ctm_topic_space-tsne-train3000-no_bg.html\"\n",
    "    #fig.write_html(save_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4ac3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_PCA(emb_matrix, word_types):\n",
    "    print(\"Running PCA on\", emb_matrix.shape, \"-dim matrix\")\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(emb_matrix)\n",
    "    df_pca = {'word_type': word_types}\n",
    "    df_pca['PC1'] = pca_result[:, 0]\n",
    "    df_pca['PC2'] = pca_result[:, 1]\n",
    "    ### Plot data with Plotly\n",
    "    fig = px.scatter(df_pca,\n",
    "                     x='PC1',\n",
    "                     y='PC2',\n",
    "                     color='word_type',\n",
    "                     opacity=0.3\n",
    "                     )\n",
    "    fig.update_traces(mode='markers', marker_size=8)\n",
    "    fig.update_layout(coloraxis={\"colorbar\":{\"dtick\":1}})\n",
    "    fig.update_xaxes(visible=False, showticklabels=False)\n",
    "    fig.update_yaxes(visible=False, showticklabels=False)\n",
    "    # fig.update_layout(paper_bgcolor=\"rgba(0,0,0,0)\", plot_bgcolor=\"rgba(0,0,0,0)\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d02caf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd396c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task\n",
       "P      96720\n",
       "PC     96720\n",
       "PCT    96720\n",
       "PT     96720\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = ['P', 'PC', 'PCT', 'PT']\n",
    "\n",
    "df = pd.read_csv(\"concreteness_norms_last_hidden_state_embs_multimodal.csv\")\n",
    "\n",
    "df[\"task\"] = [m.split(\"/\")[0] for m in df.model.tolist()]\n",
    "df[\"task\"].replace(to_replace=\"paraphrase\", value=\"P\", inplace=True)\n",
    "df[\"task\"].replace(to_replace=\"paraphrase-captioning\", value=\"PC\", inplace=True)\n",
    "df[\"task\"].replace(to_replace=\"paraphrase-captioning-translation\", value=\"PCT\", inplace=True)\n",
    "df[\"task\"].replace(to_replace=\"paraphrase-translation\", value=\"PT\", inplace=True)\n",
    "df.task.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d783d5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_type\n",
       "concrete    65400\n",
       "abstract    31320\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.task == 'P'].word_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc175d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n",
      "mean: 0.8222222222222222\n",
      "std: 0.02022480033929912\n",
      "Task: PC\n",
      "mean: 0.8245689655172412\n",
      "std: 0.024556041060134585\n",
      "Task: PCT\n",
      "mean: 0.8319444444444446\n",
      "std: 0.022934266817217618\n",
      "Task: PT\n",
      "mean: 0.8272669220945084\n",
      "std: 0.028819016458718327\n"
     ]
    }
   ],
   "source": [
    "# KMeans\n",
    "\n",
    "def compute_purity(data):\n",
    "    emb_matrix = np.array(data.iloc[:,:512])\n",
    "    true_labels = data.word_type.tolist()\n",
    "    kmeans = KMeans(n_clusters=2).fit(emb_matrix)\n",
    "    y_pred = kmeans.labels_\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    # print('purity:', purity)\n",
    "    return purity\n",
    "\n",
    "def compute_purity_balance_data(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(frac=1)\n",
    "        concrete = concrete[:word_type_counts['abstract']]\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    kmeans = KMeans(n_clusters=2).fit(emb_matrix)\n",
    "    y_pred = kmeans.labels_\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    # print('purity:', purity)\n",
    "    return purity\n",
    "\n",
    "task_purity = {'task':[], \n",
    "               'purity':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_purity = task_models.groupby(\"model\").apply(lambda x: compute_purity_balance_data(x))\n",
    "    print('mean:', model_purity.mean())\n",
    "    print('std:', model_purity.std())\n",
    "    task_purity['purity'].extend(model_purity.tolist())\n",
    "    task_purity['task'].extend([task]*len(model_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f851143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='task', ylabel='purity'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "task_purity = pd.DataFrame.from_dict(task_purity)\n",
    "sns.boxplot(data=task_purity, x=\"task\", y=\"purity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "807c860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs PC: KruskalResult(statistic=0.10707217558504323, pvalue=0.7435023649785497)\n",
      "P vs PCT: KruskalResult(statistic=3.1876286937148532, pvalue=0.07419756925486769)\n",
      "P vs PT: KruskalResult(statistic=0.9921424551859903, pvalue=0.31921930291522976)\n",
      "PC vs PCT: KruskalResult(statistic=2.0570947689420342, pvalue=0.1514987745326073)\n",
      "PC vs PT: KruskalResult(statistic=0.4283339000739055, pvalue=0.5128076125054786)\n",
      "PCT vs PT: KruskalResult(statistic=0.231562903036712, pvalue=0.6303673732611186)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "P_purity = task_purity[task_purity.task == 'P'].purity.to_list()\n",
    "PC_purity = task_purity[task_purity.task == 'PC'].purity.to_list()\n",
    "PCT_purity = task_purity[task_purity.task == 'PCT'].purity.to_list()\n",
    "PT_purity = task_purity[task_purity.task == 'PT'].purity.to_list()\n",
    "print(\"P vs PC:\", kruskal(P_purity, PC_purity))\n",
    "print(\"P vs PCT:\", kruskal(P_purity, PCT_purity))\n",
    "print(\"P vs PT:\", kruskal(P_purity, PT_purity))\n",
    "print(\"PC vs PCT:\", kruskal(PC_purity, PCT_purity))\n",
    "print(\"PC vs PT:\", kruskal(PC_purity, PT_purity))\n",
    "print(\"PCT vs PT:\", kruskal(PCT_purity, PT_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3dfa2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n",
      "mean: 0.05118804520715856\n",
      "std: 0.007769818897053615\n",
      "Task: PC\n",
      "mean: 0.05183455340327488\n",
      "std: 0.006104136577515038\n",
      "Task: PCT\n",
      "mean: 0.055948097229136885\n",
      "std: 0.00710479440293303\n",
      "Task: PT\n",
      "mean: 0.05124026348388774\n",
      "std: 0.008781108931046793\n"
     ]
    }
   ],
   "source": [
    "def compute_silhouette_balance_data(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(word_type_counts['abstract'])\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    return metrics.silhouette_score(emb_matrix, true_labels)\n",
    "\n",
    "task_sil = {'task':[], \n",
    "               'sil':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_sil = task_models.groupby(\"model\").apply(lambda x: compute_silhouette_balance_data(x))\n",
    "    print('mean:', model_sil.mean())\n",
    "    print('std:', model_sil.std())\n",
    "    task_sil['sil'].extend(model_sil.tolist())\n",
    "    task_sil['task'].extend([task]*len(model_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81df8afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs PC: KruskalResult(statistic=0.25037037037040477, pvalue=0.6168144089718366)\n",
      "P vs PCT: KruskalResult(statistic=8.277870370370351, pvalue=0.0040131170266547705)\n",
      "P vs PT: KruskalResult(statistic=0.03703703703703809, pvalue=0.8473896596867122)\n",
      "PC vs PCT: KruskalResult(statistic=7.104537037037062, pvalue=0.007688908140766365)\n",
      "PC vs PT: KruskalResult(statistic=0.548981481481519, pvalue=0.4587341591017978)\n",
      "PCT vs PT: KruskalResult(statistic=7.5737037037037, pvalue=0.005922595857839187)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "task_sil = pd.DataFrame.from_dict(task_sil)\n",
    "P_sil = task_sil[task_sil.task == 'P'].sil.to_list()\n",
    "PC_sil = task_sil[task_sil.task == 'PC'].sil.to_list()\n",
    "PCT_sil = task_sil[task_sil.task == 'PCT'].sil.to_list()\n",
    "PT_sil = task_sil[task_sil.task == 'PT'].sil.to_list()\n",
    "print(\"P vs PC:\", kruskal(P_sil, PC_sil))\n",
    "print(\"P vs PCT:\", kruskal(P_sil, PCT_sil))\n",
    "print(\"P vs PT:\", kruskal(P_sil, PT_sil))\n",
    "print(\"PC vs PCT:\", kruskal(PC_sil, PCT_sil))\n",
    "print(\"PC vs PT:\", kruskal(PC_sil, PT_sil))\n",
    "print(\"PCT vs PT:\", kruskal(PCT_sil, PT_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c886e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n",
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n",
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8899425287356323\n",
      "std: 0.006595990405191766\n",
      "Task: PC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8911079182630907\n",
      "std: 0.0070975459007081255\n",
      "Task: PCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8909642401021711\n",
      "std: 0.007167561350424478\n",
      "Task: PT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8873403575989782\n",
      "std: 0.007429911596267459\n"
     ]
    }
   ],
   "source": [
    "# Affinity propagation clustering\n",
    "def compute_purity_balance_data_aff_prop(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(frac=1)\n",
    "        concrete = concrete[:word_type_counts['abstract']]\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    aff_prop = AffinityPropagation().fit(emb_matrix)\n",
    "    y_pred = aff_prop.labels_\n",
    "    #print('emb_matrix:', emb_matrix.shape)\n",
    "    #print('n_clusters:', len(Counter(y_pred)))\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    return purity\n",
    "\n",
    "task_purity_aff_prop = {'task':[], \n",
    "                        'purity':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_purity = task_models.groupby(\"model\").apply(lambda x: compute_purity_balance_data_aff_prop(x))\n",
    "    print('mean:', model_purity.mean())\n",
    "    print('std:', model_purity.std())\n",
    "    task_purity_aff_prop['purity'].extend(model_purity.tolist())\n",
    "    task_purity_aff_prop['task'].extend([task]*len(model_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "100067e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs PC: KruskalResult(statistic=0.528854668232564, pvalue=0.46708877909445345)\n",
      "P vs PCT: KruskalResult(statistic=0.3175337373594828, pvalue=0.5730935616693535)\n",
      "P vs PT: KruskalResult(statistic=4.011709332488272, pvalue=0.04518531842577633)\n",
      "PC vs PCT: KruskalResult(statistic=0.10409748966746357, pvalue=0.746966816845346)\n",
      "PC vs PT: KruskalResult(statistic=5.587127141516109, pvalue=0.018092946741692328)\n",
      "PCT vs PT: KruskalResult(statistic=5.319114177387579, pvalue=0.02109273136104282)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "task_purity_aff_prop = pd.DataFrame.from_dict(task_purity_aff_prop)\n",
    "P_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'P'].purity.to_list()\n",
    "PC_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'PC'].purity.to_list()\n",
    "PCT_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'PCT'].purity.to_list()\n",
    "PT_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'PT'].purity.to_list()\n",
    "print(\"P vs PC:\", kruskal(P_purity, PC_purity))\n",
    "print(\"P vs PCT:\", kruskal(P_purity, PCT_purity))\n",
    "print(\"P vs PT:\", kruskal(P_purity, PT_purity))\n",
    "print(\"PC vs PCT:\", kruskal(PC_purity, PCT_purity))\n",
    "print(\"PC vs PT:\", kruskal(PC_purity, PT_purity))\n",
    "print(\"PCT vs PT:\", kruskal(PCT_purity, PT_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a2b4c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n",
      "mean: 0.9322477650063856\n",
      "std: 0.012556565012527995\n",
      "Task: PC\n",
      "mean: 0.9306673052362708\n",
      "std: 0.01357608936407527\n",
      "Task: PCT\n",
      "mean: 0.9277618135376755\n",
      "std: 0.014827165720076908\n",
      "Task: PT\n",
      "mean: 0.9289750957854406\n",
      "std: 0.013540307094867336\n"
     ]
    }
   ],
   "source": [
    "# Agglomerative (hierarchical) clustering\n",
    "def compute_purity_balance_data_agglomerative(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(frac=1)\n",
    "        concrete = concrete[:word_type_counts['abstract']]\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    agg = AgglomerativeClustering(n_clusters=None,\n",
    "                                  metric='cosine',\n",
    "                                  linkage='average',\n",
    "                                 distance_threshold=0.5).fit(emb_matrix)\n",
    "    y_pred = agg.labels_\n",
    "    #print('n_clusters:', len(Counter(y_pred)))\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    return purity\n",
    "\n",
    "task_purity_agg = {'task':[], \n",
    "                   'purity':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_purity = task_models.groupby(\"model\").apply(lambda x: compute_purity_balance_data_agglomerative(x))\n",
    "    print('mean:', model_purity.mean())\n",
    "    print('std:', model_purity.std())\n",
    "    task_purity_agg['purity'].extend(model_purity.tolist())\n",
    "    task_purity_agg['task'].extend([task]*len(model_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb5decb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs PC: KruskalResult(statistic=0.31726172315056383, pvalue=0.5732579147007723)\n",
      "P vs PCT: KruskalResult(statistic=1.9890404490691072, pvalue=0.15844124500367154)\n",
      "P vs PT: KruskalResult(statistic=1.4135708000938394, pvalue=0.23446452343773186)\n",
      "PC vs PCT: KruskalResult(statistic=1.0022685418694899, pvalue=0.3167622090626746)\n",
      "PC vs PT: KruskalResult(statistic=0.42844944874504903, pvalue=0.512750762509105)\n",
      "PCT vs PT: KruskalResult(statistic=0.12341868264594963, pvalue=0.7253558292854259)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "task_purity_agg = pd.DataFrame.from_dict(task_purity_agg)\n",
    "P_purity = task_purity_agg[task_purity_agg.task == 'P'].purity.to_list()\n",
    "PC_purity = task_purity_agg[task_purity_agg.task == 'PC'].purity.to_list()\n",
    "PCT_purity = task_purity_agg[task_purity_agg.task == 'PCT'].purity.to_list()\n",
    "PT_purity = task_purity_agg[task_purity_aff_prop.task == 'PT'].purity.to_list()\n",
    "print(\"P vs PC:\", kruskal(P_purity, PC_purity))\n",
    "print(\"P vs PCT:\", kruskal(P_purity, PCT_purity))\n",
    "print(\"P vs PT:\", kruskal(P_purity, PT_purity))\n",
    "print(\"PC vs PCT:\", kruskal(PC_purity, PCT_purity))\n",
    "print(\"PC vs PT:\", kruskal(PC_purity, PT_purity))\n",
    "print(\"PCT vs PT:\", kruskal(PCT_purity, PT_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd13a81c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
