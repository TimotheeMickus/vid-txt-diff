{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4aee6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AffinityPropagation, AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2a06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_tSNE(emb_matrix, word_types):\n",
    "    print(\"Running tSNE on\", emb_matrix.shape, \"-dim data\")\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=30, n_iter=250)\n",
    "    tsne_results = tsne.fit_transform(emb_matrix)\n",
    "    print('t-SNE done!')\n",
    "    df_tsne = {'word_type': word_types}\n",
    "    df_tsne['ax1'] = tsne_results[:, 0]\n",
    "    df_tsne['ax2'] = tsne_results[:, 1]\n",
    "    ### Plot data with Plotly\n",
    "    fig = px.scatter(df_tsne,\n",
    "                     x='ax1',\n",
    "                     y='ax2',\n",
    "                     color='word_type',\n",
    "                     opacity=0.3\n",
    "                     )\n",
    "    fig.update_traces(mode='markers', marker_size=8)\n",
    "    fig.update_layout(coloraxis={\"colorbar\":{\"dtick\":1}})\n",
    "    fig.update_xaxes(visible=False, showticklabels=False)\n",
    "    fig.update_yaxes(visible=False, showticklabels=False)\n",
    "    fig.update_layout(legend=dict(font=dict(size=10)))\n",
    "    fig.show()\n",
    "    #save_filename = \"figures/ctm_topic_space-tsne-train3000-no_bg.html\"\n",
    "    #fig.write_html(save_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4ac3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_PCA(emb_matrix, word_types):\n",
    "    print(\"Running PCA on\", emb_matrix.shape, \"-dim matrix\")\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(emb_matrix)\n",
    "    df_pca = {'word_type': word_types}\n",
    "    df_pca['PC1'] = pca_result[:, 0]\n",
    "    df_pca['PC2'] = pca_result[:, 1]\n",
    "    ### Plot data with Plotly\n",
    "    fig = px.scatter(df_pca,\n",
    "                     x='PC1',\n",
    "                     y='PC2',\n",
    "                     color='word_type',\n",
    "                     opacity=0.3\n",
    "                     )\n",
    "    fig.update_traces(mode='markers', marker_size=8)\n",
    "    fig.update_layout(coloraxis={\"colorbar\":{\"dtick\":1}})\n",
    "    fig.update_xaxes(visible=False, showticklabels=False)\n",
    "    fig.update_yaxes(visible=False, showticklabels=False)\n",
    "    # fig.update_layout(paper_bgcolor=\"rgba(0,0,0,0)\", plot_bgcolor=\"rgba(0,0,0,0)\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd396c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task\n",
       "P      96720\n",
       "PC     96720\n",
       "PCT    96720\n",
       "PT     96720\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = ['P', 'PC', 'PCT', 'PT']\n",
    "\n",
    "df = pd.read_csv(\"concreteness_norms_last_hidden_state_embs_multitask.csv\")\n",
    "\n",
    "df[\"task\"] = [m.split(\"/\")[0] for m in df.model.tolist()]\n",
    "df[\"task\"].replace(to_replace=\"paraphrase\", value=\"P\", inplace=True)\n",
    "df[\"task\"].replace(to_replace=\"paraphrase-captioning\", value=\"PC\", inplace=True)\n",
    "df[\"task\"].replace(to_replace=\"paraphrase-captioning-translation\", value=\"PCT\", inplace=True)\n",
    "df[\"task\"].replace(to_replace=\"paraphrase-translation\", value=\"PT\", inplace=True)\n",
    "df.task.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d783d5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_type\n",
       "concrete    65400\n",
       "abstract    31320\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.task == 'P'].word_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acc175d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n",
      "mean: 0.8271232439335886\n",
      "std: 0.02346877788426138\n",
      "Task: PC\n",
      "mean: 0.8235153256704981\n",
      "std: 0.025138300944223604\n",
      "Task: PCT\n",
      "mean: 0.8187100893997445\n",
      "std: 0.028661053811986872\n",
      "Task: PT\n",
      "mean: 0.8209610472541506\n",
      "std: 0.02357887347640824\n"
     ]
    }
   ],
   "source": [
    "# KMeans\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) \n",
    "\n",
    "def compute_purity(data):\n",
    "    emb_matrix = np.array(data.iloc[:,:512])\n",
    "    true_labels = data.word_type.tolist()\n",
    "    kmeans = KMeans(n_clusters=2).fit(emb_matrix)\n",
    "    y_pred = kmeans.labels_\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    # print('purity:', purity)\n",
    "    return purity\n",
    "\n",
    "def compute_purity_balance_data(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(frac=1)\n",
    "        concrete = concrete[:word_type_counts['abstract']]\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    kmeans = KMeans(n_clusters=2).fit(emb_matrix)\n",
    "    y_pred = kmeans.labels_\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    # print('purity:', purity)\n",
    "    return purity\n",
    "\n",
    "task_purity = {'task':[], \n",
    "               'purity':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_purity = task_models.groupby(\"model\").apply(lambda x: compute_purity_balance_data(x))\n",
    "    print('mean:', model_purity.mean())\n",
    "    print('std:', model_purity.std())\n",
    "    task_purity['purity'].extend(model_purity.tolist())\n",
    "    task_purity['task'].extend([task]*len(model_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f851143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='task', ylabel='purity'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "task_purity = pd.DataFrame.from_dict(task_purity)\n",
    "sns.boxplot(data=task_purity, x=\"task\", y=\"purity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "807c860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs PC: KruskalResult(statistic=0.3278931602889209, pvalue=0.5669023130610245)\n",
      "P vs PCT: KruskalResult(statistic=2.5831928339450005, pvalue=0.10800361221377876)\n",
      "P vs PT: KruskalResult(statistic=1.4015068187948128, pvalue=0.23647144294318967)\n",
      "PC vs PCT: KruskalResult(statistic=1.0903937695653565, pvalue=0.2963839787417357)\n",
      "PC vs PT: KruskalResult(statistic=0.1267993856471649, pvalue=0.7217739045452587)\n",
      "PCT vs PT: KruskalResult(statistic=0.6850396285700879, pvalue=0.4078567290721099)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "task_purity = pd.DataFrame.from_dict(task_purity)\n",
    "P_purity = task_purity[task_purity.task == 'P'].purity.to_list()\n",
    "PC_purity = task_purity[task_purity.task == 'PC'].purity.to_list()\n",
    "PCT_purity = task_purity[task_purity.task == 'PCT'].purity.to_list()\n",
    "PT_purity = task_purity[task_purity.task == 'PT'].purity.to_list()\n",
    "print(\"P vs PC:\", kruskal(P_purity, PC_purity))\n",
    "print(\"P vs PCT:\", kruskal(P_purity, PCT_purity))\n",
    "print(\"P vs PT:\", kruskal(P_purity, PT_purity))\n",
    "print(\"PC vs PCT:\", kruskal(PC_purity, PCT_purity))\n",
    "print(\"PC vs PT:\", kruskal(PC_purity, PT_purity))\n",
    "print(\"PCT vs PT:\", kruskal(PCT_purity, PT_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3dfa2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n",
      "mean: 0.051524688137925836\n",
      "std: 0.00567205730981764\n",
      "Task: PC\n",
      "mean: 0.056491768285807556\n",
      "std: 0.009292752694185497\n",
      "Task: PCT\n",
      "mean: 0.056041723803412505\n",
      "std: 0.006896596876029909\n",
      "Task: PT\n",
      "mean: 0.053867491077581195\n",
      "std: 0.007893187771623872\n"
     ]
    }
   ],
   "source": [
    "def compute_silhouette_balance_data(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(word_type_counts['abstract'])\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    return metrics.silhouette_score(emb_matrix, true_labels)\n",
    "\n",
    "task_sil = {'task':[], \n",
    "               'sil':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_sil = task_models.groupby(\"model\").apply(lambda x: compute_silhouette_balance_data(x))\n",
    "    print('mean:', model_sil.mean())\n",
    "    print('std:', model_sil.std())\n",
    "    task_sil['sil'].extend(model_sil.tolist())\n",
    "    task_sil['task'].extend([task]*len(model_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81df8afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs PC: KruskalResult(statistic=5.9737037037037055, pvalue=0.014520751247820549)\n",
      "P vs PCT: KruskalResult(statistic=8.55703703703702, pvalue=0.0034418915096161556)\n",
      "P vs PT: KruskalResult(statistic=0.944537037037037, pvalue=0.3311137567829102)\n",
      "PC vs PCT: KruskalResult(statistic=0.06750000000002387, pvalue=0.7950121719642027)\n",
      "PC vs PT: KruskalResult(statistic=1.4008333333333667, pvalue=0.23658409332186708)\n",
      "PCT vs PT: KruskalResult(statistic=2.7712037037037476, pvalue=0.09597396513197719)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "task_sil = pd.DataFrame.from_dict(task_sil)\n",
    "P_sil = task_sil[task_sil.task == 'P'].sil.to_list()\n",
    "PC_sil = task_sil[task_sil.task == 'PC'].sil.to_list()\n",
    "PCT_sil = task_sil[task_sil.task == 'PCT'].sil.to_list()\n",
    "PT_sil = task_sil[task_sil.task == 'PT'].sil.to_list()\n",
    "print(\"P vs PC:\", kruskal(P_sil, PC_sil))\n",
    "print(\"P vs PCT:\", kruskal(P_sil, PCT_sil))\n",
    "print(\"P vs PT:\", kruskal(P_sil, PT_sil))\n",
    "print(\"PC vs PCT:\", kruskal(PC_sil, PCT_sil))\n",
    "print(\"PC vs PT:\", kruskal(PC_sil, PT_sil))\n",
    "print(\"PCT vs PT:\", kruskal(PCT_sil, PT_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c533ab06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n",
      "mean: 0.8895114942528736\n",
      "std: 0.007056918304018738\n",
      "Task: PC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n",
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8919061302681992\n",
      "std: 0.006393857148621823\n",
      "Task: PCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8914272030651341\n",
      "std: 0.006161515823294774\n",
      "Task: PT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n",
      "/home/zosa/.local/lib/python3.10/site-packages/sklearn/cluster/_affinity_propagation.py:143: ConvergenceWarning: Affinity propagation did not converge, this model may return degenerate cluster centers and labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.8901021711366539\n",
      "std: 0.007089899874747479\n"
     ]
    }
   ],
   "source": [
    "# Affinity propagation clustering\n",
    "def compute_purity_balance_data_aff_prop(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(frac=1)\n",
    "        concrete = concrete[:word_type_counts['abstract']]\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    aff_prop = AffinityPropagation().fit(emb_matrix)\n",
    "    y_pred = aff_prop.labels_\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    return purity\n",
    "\n",
    "task_purity_aff_prop = {'task':[], \n",
    "                        'purity':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_purity = task_models.groupby(\"model\").apply(lambda x: compute_purity_balance_data_aff_prop(x))\n",
    "    print('mean:', model_purity.mean())\n",
    "    print('std:', model_purity.std())\n",
    "    task_purity_aff_prop['purity'].extend(model_purity.tolist())\n",
    "    task_purity_aff_prop['task'].extend([task]*len(model_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bed1c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs PC: KruskalResult(statistic=2.9536702065242646, pvalue=0.08568276575434168)\n",
      "P vs PCT: KruskalResult(statistic=2.0183946144632245, pvalue=0.15540336565357343)\n",
      "P vs PT: KruskalResult(statistic=0.2855731654364264, pvalue=0.5930714168606459)\n",
      "PC vs PCT: KruskalResult(statistic=0.37996289424859203, pvalue=0.5376230953855502)\n",
      "PC vs PT: KruskalResult(statistic=1.4840031342810516, pvalue=0.22314924363707422)\n",
      "PCT vs PT: KruskalResult(statistic=0.6862868083207059, pvalue=0.4074302537688401)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "task_purity_aff_prop = pd.DataFrame.from_dict(task_purity_aff_prop)\n",
    "P_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'P'].purity.to_list()\n",
    "PC_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'PC'].purity.to_list()\n",
    "PCT_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'PCT'].purity.to_list()\n",
    "PT_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'PT'].purity.to_list()\n",
    "print(\"P vs PC:\", kruskal(P_purity, PC_purity))\n",
    "print(\"P vs PCT:\", kruskal(P_purity, PCT_purity))\n",
    "print(\"P vs PT:\", kruskal(P_purity, PT_purity))\n",
    "print(\"PC vs PCT:\", kruskal(PC_purity, PCT_purity))\n",
    "print(\"PC vs PT:\", kruskal(PC_purity, PT_purity))\n",
    "print(\"PCT vs PT:\", kruskal(PCT_purity, PT_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32a00237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: P\n",
      "mean: 0.9285919540229888\n",
      "std: 0.013719352138136603\n",
      "Task: PC\n",
      "mean: 0.9267241379310345\n",
      "std: 0.012998400024747269\n",
      "Task: PCT\n",
      "mean: 0.9272828863346104\n",
      "std: 0.013532351215380935\n",
      "Task: PT\n",
      "mean: 0.9300766283524904\n",
      "std: 0.01468247284885529\n"
     ]
    }
   ],
   "source": [
    "# Agglomerative (hierarchical) clustering\n",
    "def compute_purity_balance_data_agglomerative(data, shuffle_data=True):\n",
    "    word_type_counts = data.word_type.value_counts()\n",
    "    abstract = data[data.word_type == 'abstract']\n",
    "    if shuffle_data is True:\n",
    "        concrete = data[data.word_type == 'concrete'].sample(frac=1)\n",
    "        concrete = concrete[:word_type_counts['abstract']]\n",
    "    else:\n",
    "        concrete = data[data.word_type == 'concrete'][:word_type_counts['abstract']]\n",
    "    balanced_data = pd.concat([abstract, concrete])\n",
    "    emb_matrix = np.array(balanced_data.iloc[:,:512])\n",
    "    true_labels = balanced_data.word_type.tolist()\n",
    "    agg = AgglomerativeClustering(n_clusters=None,\n",
    "                                  metric='cosine',\n",
    "                                  linkage='average',\n",
    "                                 distance_threshold=0.5).fit(emb_matrix)\n",
    "    y_pred = agg.labels_\n",
    "    #print('leaves:', agg.n_leaves_)\n",
    "    purity = purity_score(true_labels, y_pred)\n",
    "    return purity\n",
    "\n",
    "task_purity_agg = {'task':[], \n",
    "                   'purity':[]}\n",
    "for task in tasks:\n",
    "    print('Task:', task.upper())\n",
    "    task_models = df[df.task == task]\n",
    "    model_purity = task_models.groupby(\"model\").apply(lambda x: compute_purity_balance_data_agglomerative(x))\n",
    "    print('mean:', model_purity.mean())\n",
    "    print('std:', model_purity.std())\n",
    "    task_purity_agg['purity'].extend(model_purity.tolist())\n",
    "    task_purity_agg['task'].extend([task]*len(model_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82fbbdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P vs PC: KruskalResult(statistic=2.9536702065242646, pvalue=0.08568276575434168)\n",
      "P vs PCT: KruskalResult(statistic=2.0183946144632245, pvalue=0.15540336565357343)\n",
      "P vs PT: KruskalResult(statistic=0.2855731654364264, pvalue=0.5930714168606459)\n",
      "PC vs PCT: KruskalResult(statistic=0.37996289424859203, pvalue=0.5376230953855502)\n",
      "PC vs PT: KruskalResult(statistic=1.4840031342810516, pvalue=0.22314924363707422)\n",
      "PCT vs PT: KruskalResult(statistic=0.6862868083207059, pvalue=0.4074302537688401)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "task_purity_agg = pd.DataFrame.from_dict(task_purity_agg)\n",
    "P_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'P'].purity.to_list()\n",
    "PC_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'PC'].purity.to_list()\n",
    "PCT_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'PCT'].purity.to_list()\n",
    "PT_purity = task_purity_aff_prop[task_purity_aff_prop.task == 'PT'].purity.to_list()\n",
    "print(\"P vs PC:\", kruskal(P_purity, PC_purity))\n",
    "print(\"P vs PCT:\", kruskal(P_purity, PCT_purity))\n",
    "print(\"P vs PT:\", kruskal(P_purity, PT_purity))\n",
    "print(\"PC vs PCT:\", kruskal(PC_purity, PCT_purity))\n",
    "print(\"PC vs PT:\", kruskal(PC_purity, PT_purity))\n",
    "print(\"PCT vs PT:\", kruskal(PCT_purity, PT_purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf5a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
